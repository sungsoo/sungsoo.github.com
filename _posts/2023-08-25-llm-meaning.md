---
layout: post
title: Meaning in the age of large language models
date: 2023-08-25
categories: [artificial intelligence]
tags: [machine learning]

---

### Article Source

* [Meaning in the age of large language models](https://simons.berkeley.edu/talks/pamela-samuelson-uc-berkeley-2023-08-16)

---

# Meaning in the age of large language models

* Steven Piantadosi (UC Berkeley)
* Large Language Models and Transformers
* [Related site](https://simons.berkeley.edu/talks/steven-piantadosi-uc-berkeley-2023-08-17)


## Abstract

The recent rise in large language models profoundly changes the landscape for theories of human language. I'll discuss how these models should cause us to rethink popular ideas about grammar and language acquisition. Maybe most importantly, modern language models provide a compelling way to think about semantics and conceptual representation. I'll argue that the sense in which they possess "meanings" is likely to be analogous to how human words and concepts achieve meaning by implementing "conceptual role" theories which are at least partially accessible in the statistics present in text, even without embodied contact with the world. 


최근 대규모 언어 모델의 급부상은 인간 언어 이론의 풍경을 깊이 변화시켰습니다. 나는 이 모델들이 문법과 언어 습득에 대한 보편적인 개념을 다시 생각하게 하는 방법에 대해 논의하겠습니다. 아마도 가장 중요한 것은 현대 언어 모델이 의미론과 개념적 표현을 생각하는데 흥미로운 방식을 제공한다는 점입니다. 나는 이 모델들이 "의미"를 가진다는 면에서, 인간 언어와 개념이 세계와 실제 접촉 없이도 텍스트 내에 존재하는 통계 정보를 통해 "개념적 역할" 이론을 구현하여 의미를 얻는 방식과 유사할 것이라 주장하겠습니다.


<iframe width="600" height="400" src="https://www.youtube.com/embed/lA19zXgObKA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>