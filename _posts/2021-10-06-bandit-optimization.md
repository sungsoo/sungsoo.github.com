---
layout: post
title: Optimal Gradient-based Algorithms for Non-concave Bandit Optimization
date: 2021-10-06
categories: [computer science]
tags: [machine learning, graph mining]

---

### Article Source

* [Optimal Gradient-based Algorithms for Non-concave Bandit Optimization](https://www.youtube.com/watch?v=3ckd9ixqO3A)


---


# Optimal Gradient-based Algorithms for Non-concave Bandit Optimization

* Speaker: Qi Lei (Princeton)
* Location: Calvin Lab Auditorium and Zoom
* [https://simons.berkeley.edu/talks/optimal-gradient-based-algorithms-non-concave-bandit-optimization](https://simons.berkeley.edu/talks/optimal-gradient-based-algorithms-non-concave-bandit-optimization)
* Sampling Algorithms and Geometries on Probability Distributions

## Abstract

Bandit problems with linear or concave reward have been extensively studied, but relatively few works have studied bandits with non-concave reward. In this talk, we consider a large family of bandit problems where the unknown underlying reward function is non-concave, including the low-rank generalized linear bandit problems and two-layer neural network with polynomial activation bandit problem. For the low-rank generalized linear bandit problem, we provide a minimax-optimal algorithm in the dimension, refuting both conjectures in (Lu et al. 2021) and (Jun et al. 2019). Our algorithms are based on a unified zeroth-order optimization paradigm that applies in great generality and attains optimal rates in several structured polynomial settings (in the dimension). We further demonstrate the applicability of our algorithms in RL in the generative model setting, resulting in improved sample complexity over prior approaches. Finally, we show that the standard optimistic algorithms (e.g., UCB) are sub-optimal by dimension factors. In the neural net setting (with polynomial activation functions) with noiseless reward, we provide a bandit algorithm with sample complexity equal to the intrinsic algebraic dimension. Again, we show that optimistic approaches have worse sample complexity, polynomial in the extrinsic dimension (which could be exponentially worse in the polynomial degree).


<iframe width="600" height="400" src="https://www.youtube.com/embed/3ckd9ixqO3A" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>