---
layout: post
title: Understanding Learning and Computation through Symmetry
date: 2025-02-02
categories: [artificial intelligence]
tags: [machine learning]

---

### Article Source


* [Causal Representation Learning in the Context of Perturbation Screens](https://www.youtube.com/watch?v=83uzaYXwzAM)

---


# Understanding Learning and Computation through Symmetry

## Abstract

* Hidenori Tanaka, Research Scientist, NTT Research, Harvard University
* Friday, September 15, 2023, 2:00pm–3:00pm

Once described as alchemy, a quantitative science of machine learning is emerging. This talk will seek to unify the scientific approaches taken in machine learning, neuroscience, and physics. We will show how conceptual and mathematical tools in physics, such as symmetry, may illuminate the universal mechanisms behind learning and computation in biological and artificial neural networks. We plan to (i) generalize Noether’s theorem in physics to show how scale symmetry of normalization makes learning more stable and efficient, (ii) propose a new framework for studying compositional generalization in generative models, and (iii) identify phase transitions in the loss landscapes of self-supervised learning as a potential cause of a failure mode called dimensional collapse.

<iframe width="600" height="400" src="https://www.youtube.com/embed/83uzaYXwzAM?si=a5Na1idf956UB552" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


