---
layout: post
title:  Inference Techniques
date: 2024-12-18
categories: [artificial intelligence]
tags: [machine learning]

---

# Inference Techniques

# 추론 기법

AGI 추론 시스템은 사용자 응답성, 가용성 및 효율성을 보장해야 하며, 이는 훈련 단계에서 대규모 모델의 잠재력을 최대한 활용하고 사용자와 시스템의 상호 작용 방식을 혁신하는 데 도움이 됩니다. 따라서 본 절에서는 자기 회귀적 디코딩 가속화, 요청 스케줄링 균형 조정, 클러스터 내에서 다양한 기능을 가진 대규모 모델을 서비스하는 등 향후 시스템 개발에 영감을 줄 수 있는 다양한 기법들을 개괄적으로 살펴봅니다.

## 디코딩 알고리즘

본 논문에서는 정확도를 훼손하지 않으면서 디코딩 성능을 최대화하는 정확한 디코딩 가속에 주목합니다. Miao 등(2023)은 샘플링 전략, 비자기 회귀적 디코딩, 반자기 회귀적 디코딩, 블록 병렬 디코딩 등 다양한 근사 방법에 대한 포괄적인 검토를 제공합니다.

많은 연구들이 여러 토큰을 한 번에 생성할 가능성을 높여 병렬 계산을 활용하는 투기적 디코딩 아이디어를 탐구합니다. 일반적으로 투기적 디코딩 프로세스는 여러 단계를 예측하는 효율적인 드래프트 모델로 시작하며, 생성된 제안은 목표 모델을 통해 검증됩니다. 하지만 드래프트 모델을 가볍게 유지하면서도 유용한 추측을 생성하는 방법, 아키텍처 변경과 미세 조정을 최소화하여 빠르게 적응하는 방법, 드래프트 모델을 더 효과적으로 배포하는 방법 등 해결해야 할 과제들이 많습니다. 

가장 간단하면서도 효과적인 변형은 프롬프트 조회 디코딩(Saxena, 2023)으로, 드래프트 모델 대신 기존 데이터베이스에서 접두사 문자열 매칭을 통해 후보 토큰을 생성하는 것입니다. 이 모델 독립적인 접근 방식은 미세 조정이나 모델 변경 없이 매우 빠르게 디코딩할 수 있지만, 성능은 문자열 풀의 품질과 다양성에 크게 의존합니다. 후보를 더 빠르게 검증하기 위해 SpecInfer(Miao et al., 2024)는 드래프트 모델의 출력을 각 노드가 후보 토큰인 토큰 트리로 구성하여, 각 노드의 정확성을 기본 모델이 병렬로 효율적으로 검사할 수 있도록 합니다. 유사한 아이디어로 Medusa(Cai et al., 2024a)는 특수 마스크 패턴을 통해 모든 토큰을 동시에 검사하는 트리 어텐션 메커니즘을 도입합니다. Self-speculative decoding(Zhang et al., 2023k)은 드래프트 모델을 완전히 버리고 중간 레이어의 일부를 선택적으로 건너뛰어 후보 시퀀스를 생성합니다.

## 하드웨어 인지 알고리즘

하드웨어 인지 알고리즘은 디코딩 단계에서 특히 효과적이고 매력적입니다. Flash-Decoding은 시퀀스 차원을 따라 분할하고 이 블록들을 Flash-Attention으로 병렬 처리하여 KV 캐시와 통계를 사용하여 결과를 집계합니다. FlashDecoding++(Hong et al., 2023a)는 Flash-Decoding의 한계를 해결하고 시스템 수준의 최적화를 적용하여 디코딩 절차를 가속화합니다. 비동기 소프트맥스, 이중 버퍼링을 사용한 최적화된 플랫 GEMM 연산, 하드웨어 자원 적응을 위한 휴리스틱 기반 데이터 흐름 등을 도입하여 HuggingFace 대비 4배 이상 속도 향상을 달성했습니다. 

## 요약

본 절에서는 AGI 추론 시스템의 성능을 향상시키기 위한 다양한 디코딩 가속 기법들을 소개했습니다. 특히 투기적 디코딩, 하드웨어 인지 알고리즘 등을 중심으로 자세히 살펴보았습니다. 이러한 기법들은 대규모 모델의 실제적인 활용을 위한 중요한 토대가 될 것입니다. 

**핵심 키워드:** 자기 회귀적 디코딩, 투기적 디코딩, 하드웨어 인지 알고리즘, Flash-Decoding, SpecInfer, Medusa

