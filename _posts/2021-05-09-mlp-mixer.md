---
layout: post
title: MLP-Mixer; An all-MLP Architecture for Vision
date: 2021-05-09
categories: [computer science]
tags: [machine learning, data management]

---

### Article Source

* [MLP-Mixer; An all-MLP Architecture for Vision](https://www.youtube.com/watch?v=7K4Z8RqjWIk)

---

# MLP-Mixer
## An all-MLP Architecture for Vision 

* [Paper](https://arxiv.org/abs/2105.01601)


## Abstract
*Convolutional Neural Networks* have dominated computer vision for nearly 10 years, and that might finally come to an end. First, Vision Transformers (ViT) have shown remarkable performance, and now even simple MLP-based models reach competitive accuracy, as long as sufficient data is used for pre-training. This paper presents MLP-Mixer, using MLPs in a particular weight-sharing arrangement to achieve a competitive, high-throughput model and it raises some interesting questions about the nature of learning and inductive biases and their interaction with scale for future research.

<iframe width="600" height="400" src="https://www.youtube.com/embed/7K4Z8RqjWIk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Convolutional Neural Networks (CNNs) are the go-to model for computer vision. Recently, attention-based networks, such as the *Vision Transformer*, have also become popular. In this paper we show that while convolutions and attention are both sufficient for good performance, neither of them are necessary. We present MLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs). MLP-Mixer contains two types of layers: one with MLPs applied independently to image patches (i.e. "mixing" the per-location features), and one with MLPs applied across patches (i.e. "mixing" spatial information). When trained on large datasets, or with modern regularization schemes, MLP-Mixer attains competitive scores on image classification benchmarks, with pre-training and inference cost comparable to state-of-the-art models. We hope that these results spark further research beyond the realms of well established CNNs and Transformers. 

<iframe width="600" height="400" src="https://www.youtube.com/embed/7FHmzEBNzro" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<iframe width="600" height="400" src="https://www.youtube.com/embed/KQmZlxdnnuY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>