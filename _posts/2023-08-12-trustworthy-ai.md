---
layout: post
title: Trustworthy AI - A Computational Perspective
date: 2023-08-12
categories: [artificial intelligence]
tags: [machine learning]

---

### Article Source

* [Trustworthy AI - A Computational Perspective](https://www.youtube.com/watch?v=3aHJLeg1_jo)

---

# Trustworthy AI - A Computational Perspective

* Presenters: Haochen Liu, Yiqi Wang, Wenqi Fan, Xiaorui Liu, Jamell Dacon, Lingjuan Lyu and Jiliang Tang
* Web: [https://sites.google.com/msu.edu/trustworthy-ai/](https://sites.google.com/msu.edu/trustworthy-ai/)
* [Slides](https://drive.google.com/file/d/1fD4lIHYZ3VptXNUyoeVI67_NTC6ry6bJ/view?pli=1)



## Introduction

The past few decades have witnessed the rise of artificial intelligence (AI) technology. However, recent studies show evidence that AI algorithms may not be trustworthy. For example, they could be vulnerable to slight perturbations of input data; they could undermine fairness by showing bias and stereotypes towards certain groups of people; and their decisions could be hard to explain due to their opaque model architectures. With the widespread use of AI applications in our daily life, whether an AI algorithm is trustworthy or not has become a problem of great concern to researchers, developers and users. Recently, a great amount of research on trustworthy AI has emerged. In this tutorial, we aim to provide a comprehensive overview of the cutting-edge research progress on trustworthy AI from a computational perspective. Specifically, we focus on the six most important dimensions in realizing trustworthy AI: (i) Privacy, (ii) Safety & Robustness, (iii) Explainability (iv) Non-discrimination & Fairness, (v) Environmental Well-Being and (vi) Accountability & Auditability. We will introduce the latest technologies and real-world applications in each dimension according to a taxonomy, and discuss the accordant and conflicting interactions among various dimensions. Besides, we will discuss potential future research directions in this field. We expect that researchers and practitioners can gain a broad overview and a deep insight of trustworthy AI from this tutorial, so as to advance the progress of this field.


<iframe width="600" height="400" src="https://www.youtube.com/embed/3aHJLeg1_jo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>


## Outline

### Introduction and Concepts

In this part, we will first briefly introduce the background knowledge of the AI technology, including its achievements and current development status. Then we introduce the concept of trustworthy AI, and clarify the motivation for studying trustworthy AI by showing real-world examples of the untrustworthy sides of AI systems. Next, we generally describe the six important and concerning dimensions for trustworthy AI with specific examples. Finally, we further articulate the definition of trustworthy AI by comparing it with similar concepts such as Ethical AI, etc.



### Privacy

The success of modern AI systems is built upon data which contains a large amount of private and sensitive information, such as credit card data and medical records. To establish trustworthy AI systems, we must guarantee the safety of private and sensitive information carried by the data and models which could be potentially exposed throughout the AI systems. In this part, we will introduce mainstream privacy-preserving AI technologies such as confidential computing, federated learning and differential privacy, followed by discussions on applications in real systems.  



### Safety & Robustness

Safety & Robustness describes the ability of an AI system to be robust to noisy perturbations of the inputs and to be able to make secure decisions. Recent studies show that AI systems can be very sensitive to perturbations of the inputs, which makes it dangerous to apply them in safety-critical scenarios. For example, autonomous vehicles can be fooled by altered road signs. In this part, we will introduce recent research on the safety and robustness of AI, including the advanced model attacking and defense strategies and real-world applications.



### Explainability

A trustworthy AI system requires explainability, which means that the decision process of an AI system should be able to be explained to stakeholders. For example, in a life-critical scenario such as AI-based disease diagnosis, a black-box decision is not acceptable. The inference mechanism should be transparent to doctors and patients to ensure that the diagnosis is accurate. In this part, we will introduce recent studies on the explainability of AI with real-world applications. 



### Non-discrimination & Fairness

It has been shown that AI algorithms can make biased decisions that are skewed towards a particular individual or a group. For example, some face recognition algorithms have difficulties in detecting faces of African Americans; dialogue models can be biased towards females and African Americans by generating more offensive and negative responses for these groups. In this part, we will introduce recent studies on the fairness of AI, including a taxonomy of bias and fairness in AI, advanced debiasing methods and their real-world applications.



### Environmental Well-Being

A trustworthy AI system should be sustainable and environmentally friendly. However, recent studies show that training a large-scale AI model can cost a great amount of a carbon emission, which poses a threat to the ecological environment. In this part, we will introduce recent research on the environmental well-being of AI with real-world applications.



### Accountability & Auditability

Auditability & Accountability requires an AI system to be assessed by a third party, and hold someone responsible for an AI failure, especially in critical applications. In this part, we will introduce the latest auditability & accountability strategies with real-world applications.



### Dimension Interactions & Future Directions

It has been shown that there are accordance and conflict among different dimensions of trustworthy AI. For example, the robustness and interpretability of deep neural networks are tightly connected and robust models tend to be more interpretable. In this part, we will introduce the recent studies on the interactions among various dimensions of trustworthy AI, and conclude the tutorial with potential future research directions.