---
layout: post
title: Next-Generation Recurrent Network Models
date: 2021-06-27
categories: [computer science]
tags: [machine learning, graph mining]

---

### Article Source

* [Next-generation recurrent network models for cognitive neuroscience](https://www.youtube.com/watch?v=kPZ3vencYxo)


---

## Next-generation recurrent network models for cognitive neuroscience

* Dr. Guangyu Robert Yang, Dept. of Brain and Cognitive Sciences (BCS),  
* EECS Dept., Schwarzman College of Computing (SCC), MIT

## Abstract

*Recurrent Neural Networks* (RNNs) trained with machine learning techniques on cognitive tasks have become a widely accepted tool for neuroscientists. In comparison to traditional computational models in neuroscience, RNNs can offer substantial advantages at explaining complex behavior and neural activity patterns. Their use allows rapid generation of mechanistic hypotheses for cognitive computations. RNNs further provide a natural way to flexibly combine bottom-up biological knowledge with top-down computational goals into network models. However, early works of this approach are faced with fundamental challenges. In this talk, I will discuss some of these challenges, and several recent steps that we took to partly address them and to build **next-generation RNN models** for cognitive neuroscience.â€‹


<iframe width="600" height="400" src="https://www.youtube.com/embed/Eq-chOIbOwM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

 