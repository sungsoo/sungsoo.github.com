---
layout: post
title: Large Multimodal Models
date: 2023-07-27
categories: [artificial intelligence]
tags: [machine learning]

---

### Article Source

* [Large Multimodal Models](https://www.youtube.com/watch?v=mkI7EPD1vp8)

---

# Large Multimodal Models

* [CVPR2023 Tutorial on Vision Foundation Models](https://www.youtube.com/playlist?list=PLB1k029in3UhWaAsXP1DGq8qEpWxW0QyS)
* CVPR 2023 Tutorial on "Recent Advances in Vision Foundation Models"
- Large Multimodal Models: Towards Building and Surpassing Multimodal GPT-4
- By Chunyuan Li (Microsoft)


## Abstract

Deep learning algorithms are well-known to have a propensity for fitting the training data very well and memorize idiosyncratic properties in the training examples. From a scientific perspective, understanding memorization in deep neural networks shed light on how those models generalize. From a practical perspective, understanding memorization is crucial to address privacy and security issues related to deploying models in real world applications. In this talk,  we present a series of studies centered at quantifying memorization in neural language models. We explain why in many real world tasks, memorization is necessary for optimal generalization. We also present quantitative studies on memorization, forgetting and unlearning of both vision and language models, to better understand the behaviors and implications of memorization in those models.

<iframe width="600" height="400" src="https://www.youtube.com/embed/mkI7EPD1vp8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>