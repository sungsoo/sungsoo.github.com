---
layout: post
title:  Large-Scale Training
date: 2024-12-16
categories: [artificial intelligence]
tags: [machine learning]

---

# Large-Scale Training (대규모 모델 학습)

대규모 모델 학습은 현대 하드웨어에서 여러 가지 어려움에 직면합니다. 모델이 너무 커져 단일 GPU에 적합하지 않게 되고, 메모리 요구량이 증가하며, 병렬 처리를 통한 속도 향상이 필요해졌기 때문입니다. 이러한 문제를 해결하기 위해 다양한 병렬 처리 기법과 메모리 관리 기법이 연구되고 있습니다.

## 병렬 컴퓨팅

클러스터 환경에서 여러 컴퓨팅 유닛을 사용하여 대규모 언어 모델을 학습할 때, 주로 4가지 병렬 처리 방식(DDP, TP, PP, SP)이 사용됩니다.

* **분산 데이터 병렬 처리(DDP):** 모델을 복제하고 데이터를 분할하여 각 모델에 할당하는 가장 간단한 방식입니다. DeepSpeed, FairScale, Megatron-LM 등의 프레임워크에서 사용됩니다.
* **텐서 병렬 처리(TP):** 모델 파라미터를 여러 부분으로 나누어 각 GPU에 할당합니다. 데이터는 분할된 파라미터를 병렬로 처리한 후 결과를 합칩니다.
* **파이프라인 병렬 처리(PP):** 모델 레이어를 여러 GPU에 분산시켜 데이터를 순차적으로 처리합니다.
* **시퀀스 병렬 처리(SP):** 긴 컨텍스트 처리를 위해 시퀀스를 분할하여 처리합니다.

각 병렬 처리 방식은 장단점이 있으며, 클러스터 구성에 따라 적절한 방식을 선택해야 합니다. 최근에는 Alpha, HexGen, FlexFlow와 같은 자동 병렬화 시스템이 개발되어 하드웨어 자원을 최대한 활용하는 방안을 모색하고 있습니다.

## 메모리 관리

대규모 모델 학습에서 메모리 관리는 매우 중요한 문제입니다. 특히, KV 캐시는 모델 가중치와 활성화 값보다 더 많은 메모리를 차지할 수 있습니다. 이러한 문제를 해결하기 위해 다양한 메모리 관리 기법이 제시되었습니다.

* **페이징 어텐션:** KV 캐시를 비연속적인 메모리 블록으로 분할하여 메모리 단편화 문제를 해결하고 메모리 사용 효율을 높입니다.
* **적응형 KV 캐시 압축:** 사용 빈도가 낮은 토큰을 제거하여 메모리 사용량을 줄입니다.
* **핵심 토큰 유지:** 중요한 토큰만 유지하여 성능 저하 없이 메모리 사용량을 줄입니다.
* **무한 LLM:** 어텐션 계산을 작은 서브루틴으로 분할하고, 지정된 서버가 KV 캐시를 관리하여 데이터 센터 전체의 GPU와 CPU 메모리를 효율적으로 활용합니다.

## 추가적인 기법

* **CPU 오프로딩:** 가중치나 KV 캐시를 CPU로 이동하여 GPU 메모리를 확보합니다.
* **그래디언트 체크포인팅:** 역전파 계산 시 일부 계산 결과를 버려 최대 메모리 사용량을 줄입니다.

## 결론

대규모 모델 학습을 위한 효율적인 병렬 처리와 메모리 관리 기법은 지속적으로 발전하고 있습니다. 이러한 기술들은 더욱 크고 복잡한 모델을 학습하고 배포하는 데 필수적이며, 인공지능 기술의 발전을 이끌어낼 것입니다.

**핵심 키워드:** 대규모 모델 학습, 병렬 처리, 메모리 관리, DDP, TP, PP, SP, KV 캐시, 그래디언트 체크포인팅

