---
layout: post
title: What is DeepSeek? AI Model Basics Explained
date: 2025-03-02
categories: [artificial intelligence]
tags: [machine learning]

---

### Article Source


* [What is DeepSeek? AI Model Basics Explained](https://www.youtube.com/watch?v=KTonvXhsxpc)

---


# What is DeepSeek? AI Model Basics Explained

## Abstract

Want to learn more about how to choose the right AI foundation model? Read the Ebook here â†’ https://ibm.biz/BdGGqN

Learn more about DeepSeek here â†’ https://ibm.biz/BdGGqt

Want to hear more about the facts and hype of DeepSeek from our Mixture of Experts? Watch here â†’ https://ibm.biz/BdGGqk

Explore the unique capabilities of DeepSeek, an innovative AI reasoning model. ðŸŒŸ Martin Keen and Aaron Baughman discuss the evolution of DeepSeek models, focusing on DeepSeek-R1. Learn how it uses chain of thought reasoning, reinforcement learning, and expert architectures to achieve top-tier performance efficiently. ðŸš€

AI news moves fast. Sign up for a monthly newsletter for AI updates from IBM â†’ https://ibm.biz/BdGGq6

<iframe width="600" height="400" src="https://www.youtube.com/embed/KTonvXhsxpc?si=G8a4U5yKkIuP89kB" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


## DeepSeek facts vs hype, model distillation, and open source competition

Letâ€™s bust some early myths about DeepSeek. In episode 40 of Mixture of Experts, join host Tim Hwang along with experts Aaron Baughman, Chris Hay and Kate Soule. Last week, we covered the release of DeepSeek-R1; now that the entire world is up to speed, letâ€™s separate the facts from the hype. Next, what is model distillation and why does it matter for competition in AI? Finally, Sam Altman among other tech CEOs shared his response to DeepSeek. Will R1 radically change the open-source strategy of other tech giants? Find out all this and more on Mixture of Experts.

<iframe width="600" height="400" src="https://www.youtube.com/embed/jC0MGFDawWg?si=cgWnFbYmRJ-xSUdZ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## The Engineering Unlocks Behind DeepSeek

Chinese AI company DeepSeek recently made waves when it announced R1, an open-source reasoning model that it claimed achieved comparable performance to OpenAIâ€™s o1, at a fraction of the cost. But for those following AI developments closely, DeepSeek and R1 didnâ€™t come out of nowhere.

In this episode of YC Decoded, General Partner Diana Hu breaks down the key engineering optimizations behind DeepSeek's remarkable new models â€” and contextualizes them within the broader history of recent AI breakthroughs.

<iframe width="600" height="400" src="https://www.youtube.com/embed/4Tmn-XP93m4?si=X1KDijhHhLLHkcYG" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

# DeepSeek R1 Theory Overview


## Abstract

Here's an overview of the DeepSeek R1 paper. I read the paper this week and I was fascinated by the methods, however it was a bit difficult to follow what was going on with all the models being used.

I found a neat map of the methodology which I'll be using in this tutorial to walk you through the paper.

I strongly recommend you to still read the paper over here:

ðŸ“Œ PAPER: [https://arxiv.org/pdf/2501.12948](https://arxiv.org/pdf/2501.12948)

<iframe width="600" height="400" src="https://www.youtube.com/embed/QdEuh2UVbu0?si=B02lth4za214ugAT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


## DeepSeek-R1 Paper Explained - A New RL LLMs Era in AI?

## Abstract
In this video, we dive into the groundbreaking DeepSeek-R1 research paper, titled "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning". This paper introduces the models DeepSeek-R1-Zero and DeepSeek-R1, open-source reasoning models that rivals the performance of top-tier models like OpenAI's o1!

Here's a quick overview of what we'll cover:

* Training a Large Language Model (LLM) using Reinforcement Learning (RL) only in post-training, without Supervised Fine-tuning (SFT).
* Rule-based Reinforcement Learning (RL) used DeepSeek-R1 for large-scale RL training.
* Intriguing insights including the "aha" moment.
* DeepSeek-R1 Training Pipeline
* Performance results

* Written review - [https://aipapersacademy.com/deepseek-r1/](https://aipapersacademy.com/deepseek-r1/)
* Paper - [https://arxiv.org/abs/2501.12948](https://arxiv.org/abs/2501.12948)
* Project page - [https://github.com/deepseek-ai/DeepSeek-R1/tree/main](https://github.com/deepseek-ai/DeepSeek-R1/tree/main)


<iframe width="600" height="400" src="https://www.youtube.com/embed/DCqqCLlsIBU?si=yx6nrVhHN5h3qQ55" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>