---
layout: post
title: Graph Representation Learning
date: 2021-07-22
categories: [computer science]
tags: [machine learning, graph mining]

---

### Article Source

* [GCLR Talk by Dr William L Hamilton](https://www.youtube.com/watch?v=e2zkrSEtV9Y)


---


# Graph Representation Learning: Recent Advances and Open Challenges

* Graphs and more Complex structures for Learning and Reasoning (GCLR) workshop was held at AAAI 2021. For more details about the workshop, please visit website: [https://sites.google.com/view/gclr2021/](https://sites.google.com/view/gclr2021/)​. 

### Speaker's Bio

Dr. William L  Hamilton is an Assistant Professor in the School of Computer Science at McGill University. His research focuses on deep learning, graph representation learning, and natural language processing—with an emphasis on deep learning with structured, relational data. In this talk, William will talk about Graph Neural Networks (GNNs), fundamental limitations of the current GNN paradigm and recent progress in the area.

## AAAI 2021 Talk

<iframe width="600" height="400" src="https://www.youtube.com/embed/e2zkrSEtV9Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## Abstract

Graph-structured data is ubiquitous throughout the natural and social sciences, from telecommunication networks to quantum chemistry. Building relational inductive biases into deep learning architectures is crucial if we want systems that can learn, reason, and generalize from this kind of data. Recent years have seen a surge in research on graph representation learning, most prominently in the development of graph neural networks (GNNs). Advances in GNNs have led to state-of-the-art results in numerous domains, including chemical synthesis, 3D-vision, recommender systems, question answering, and social network analysis. In the first part of this talk I will provide an overview and summary of recent progress in this fast-growing area, highlighting foundational methods and theoretical motivations. In the second part of this talk I will discuss fundamental limitations of the current GNN paradigm. Finally, I will conclude the talk by discussing recent progress my group has made in advancing graph representation learning beyond the GNN paradigm.

## ACM KDD 2020 Talk

<iframe width="600" height="400" src="https://www.youtube.com/embed/iVP6a92ffvs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>