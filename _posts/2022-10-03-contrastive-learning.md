---
layout: post
title: Contrastive Learning in PyTorch 
date: 2022-10-03
categories: [computer science]
tags: [machine learning, graph mining]

---

### Article Source

* [Contrastive Learning in PyTorch](https://www.youtube.com/watch?v=u-X_nZRsn5M)


---

# Contrastive Learning in PyTorch

▬▬ Notes ▬▬▬▬▬▬▬▬▬▬▬

Two small things I realized when editing this video

- SimCLR uses two separate augmented views as positive samples 
- Many frameworks have separate projection heads on the learned representations
which transforms them additionally for the contrastive loss

▬▬ Papers/Sources ▬▬▬▬▬▬▬

- Intro: [https://sthalles.github.io/a-few-words-on-representation-learning/](https://sthalles.github.io/a-few-words-on-representation-learning/)
- Survey: [https://arxiv.org/ftp/arxiv/papers/2010/2010.05113.pdf](https://arxiv.org/ftp/arxiv/papers/2010/2010.05113.pdf)
- Supervised Contrastive Learning: [https://arxiv.org/abs/2004.11362](https://arxiv.org/abs/2004.11362)
- Contrastive Loss: [https://medium.com/@maksym.bekuzarov/losses-explained-contrastive-loss-f8f57fe32246](https://medium.com/@maksym.bekuzarov/losses-explained-contrastive-loss-f8f57fe32246)
- Triplet Loss: [https://towardsdatascience.com/triplet-loss-advanced-intro-49a07b7d8905](https://towardsdatascience.com/triplet-loss-advanced-intro-49a07b7d8905)
- NT-Xent Loss: [https://medium.datadriveninvestor.com/simclr-part-2-the-encoder-projection-head-and-loss-function-809a64f30d4a](https://medium.datadriveninvestor.com/simclr-part-2-the-encoder-projection-head-and-loss-function-809a64f30d4a)
- SimCLR


<iframe width="600" height="400" src="https://www.youtube.com/embed/u-X_nZRsn5M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>