---
layout: post
title: How Do We Build a General Intelligence?
date: 2024-12-30
categories: [artificial intelligence]
tags: [machine learning]

---

### Article Source


* [How Do We Build a General Intelligence?](https://www.youtube.com/watch?v=HEp4TOrkwV4)

---



# How Do We Build a General Intelligence?

* [Slides](https://cims.nyu.edu/~andrewgw/andrewiclr2024agi.pdf)

## Abstract

The talk is in five parts: 1) How do we build systems that learn and generalize, from a perspective of probability and compression? Can we use these principles to resolve mysterious generalization behaviour in deep learning? 2) Is it possible to build general-purpose AI systems in light of results like the no free lunch theorems? 3) What are the prescriptions for general intelligence? 4) What are the demonstrations of those principles in scientific settings? 5) What are we far away from solving?


### Associated Papers:

(1) "The No Free Lunch Theorem, Kolmogorov Complexity, and the Role of Inductive Biases in Machine Learning" ICML 2024 [https://arxiv.org/abs/2304.05366](https://arxiv.org/abs/2304.05366)

(2) "Bayesian Deep Learning and a Probabilistic Perspective of Generalization" NeurIPS 2020 [https://arxiv.org/abs/2002.08791](https://arxiv.org/abs/2002.08791)

(3) "Large Language Models are Zero-Shot Time Series Forecasters" NeurIPS 2023 [https://arxiv.org/abs/2310.07820](https://arxiv.org/abs/2310.07820)

(4)  "Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra" NeurIPS 2023 [https://arxiv.org/abs/2309.03060](https://arxiv.org/abs/2309.03060)

<iframe width="600" height="400" src="https://www.youtube.com/embed/HEp4TOrkwV4?si=XCG1xUcoQdt13xXi" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>