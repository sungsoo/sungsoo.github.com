---
layout: post
title: Text2SQL; The Dream versus Reality 
date: 2024-03-04
categories: [artificial intelligence]
tags: [machine learning]

---

### Article Source


* [Text2SQL; The Dream versus Reality](https://www.youtube.com/watch?v=xmzda44hUgk)

---

# Text2SQL; The Dream versus Reality

* Text2SQL: The Dream versus Reality
* Speaker: Laurel Orr


## Abstract


In this talk we explore the nuanced application of Large Language Models (LLMs) in Text2SQL for data-centric tasks. The talk outlines the transformative potential of LLMs in making data insights accessible through natural language, while critically examining the hurdles such as the 80% solution dilemma, the translation of business terminology, and privacy concerns. Through the lens of the DuckDB-NSQL case study, we proposes solutions like a semantic layer and modular pipelines, showcasing a novel approach that leverages an intermediate language for enhanced SQL compilation. This session not only highlights the technological advancements but also the pragmatic challenges and strategies for deploying LLMs in real-world scenarios.

<iframe width="600" height="400" src="https://www.youtube.com/embed/xmzda44hUgk?si=23qxG9ih9rJVJdH5" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

이번 발표에서는 텍스트를 SQL로 변환하는 작업(Text2SQL)에 대형 언어 모델(LLM)을 섬세하게 적용하는 방법에 대해 살펴보겠습니다.
이 발표는 LLM이 자연어를 통해 데이터 분석 결과를 쉽게 접근할 수 있게 하는 변혁적인 잠재력을 설명하는 동시에, 80% 해결 딜레마, 비즈니스 용어 변환, 개인 정보 보호 문제와 같은 난제를 비판적으로 검토합니다.

DuckDB-NSQL 사례 연구를 통해 의미 계층 및 모듈형 파이프라인과 같은 솔루션을 제안하며, 향상된 SQL 컴파일을 위한 중간 언어를 활용하는 새로운 접근 방식을 선보입니다. 이 세션은 기술적 발전뿐만 아니라 실제 시나리오에서 LLM을 배포하는 데 따른 실용적인 문제점과 전략도 강조합니다.

### 주요 내용

* 텍스트를 SQL로 변환하는 작업(Text2SQL)
* 대형 언어 모델(LLM)의 활용
* LLM 활용의 장점 (데이터 분석 결과의 자연어 접근성 향상)
* LLM 활용의 난제 (80% 해결 딜레마, 비즈니스 용어 변환, 개인 정보 보호 문제)
* DuckDB-NSQL 사례 연구
* LLM 활용을 위한 솔루션 (의미 계층, 모듈형 파이프라인, 중간 언어 활용)
* 실제 시나리오에서의 LLM 배포 전략

## Bio
Laurel Orr am currently a researcher at Numbers Station part of the Numbers Station Labs where she think about all things foundation models and data tasks.

Before Numbers Station, she was a PostDoc at Stanford working with Chris Ré in the Hazy Research Lab. In August of 2019, she graduated with a PhD from Paul G Allen School for Computer Science and Engineering at the University of Washington in Seattle, where she was part of the Database Group and advised by Dan Suciu and Magdalena Balazinska.

--
